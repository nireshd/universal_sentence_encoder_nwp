{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use_next_word_prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1ppyv/v5kjfdadh76aGkM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nireshd/universal_sentence_encoder_nwp/blob/main/use_next_word_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBMNQRuotQG8"
      },
      "source": [
        "from keras.models import Sequential, load_model\r\n",
        "import pandas as pd\r\n",
        "import tensorflow_hub as hub\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "import tensorflow as tf\r\n",
        "import warnings\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\r\n",
        "\r\n",
        "def load_obj(name ):\r\n",
        "    with open(name + '.pkl', 'rb') as f:\r\n",
        "        return pickle.load(f)\r\n",
        "    \r\n",
        "def embed(input):\r\n",
        "    return encoderModel(input)    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxypUV11tRIS"
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/pencil_assignment/word_embedding.h5')\r\n",
        "tokenizer = load_obj('/content/drive/My Drive/Colab Notebooks/pencil_assignment/tokenizer_saved')\r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUsh6fLruHxE",
        "outputId": "a22dbd92-09a9-4657-ff44-264fb2043533"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "input_text = input().strip().lower()\r\n",
        "encoded_text = tokenizer.texts_to_sequences([input_text])[0]\r\n",
        "pad_encoded = pad_sequences([encoded_text], maxlen=3, truncating='pre')\r\n",
        "print(encoded_text, pad_encoded)\r\n",
        "for i in (model.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\r\n",
        "    pred_word = tokenizer.index_word[i]\r\n",
        "    print(\"Next word suggestion:\",pred_word)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the third element of the periodic table is\n",
            "[1, 110, 5, 1, 19] [[ 5  1 19]]\n",
            "Next word suggestion: troops\n",
            "Next word suggestion: leader\n",
            "Next word suggestion: state\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcp3hkjNxoIR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}